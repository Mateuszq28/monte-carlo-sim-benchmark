{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "porównanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, rc\n",
    "from scipy.stats import chisquare, kstest, norm, levene, ttest_ind, boxcox\n",
    "from scipy.stats import probplot, kurtosis, skew, spearmanr, wilcoxon, chi2_contingency\n",
    "from scipy.stats import mannwhitneyu, kruskal, pearsonr, ttest_rel, f_oneway\n",
    "import pylab\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import PowerTransformer, QuantileTransformer\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "from PIL import Image\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funkcje z compare.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_file(filename):\n",
    "    file = open(filename, 'r')\n",
    "    data = json.load(file)\n",
    "    file.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def cube_list2array(d):\n",
    "    d['cube'] = np.asarray(d['cube'])\n",
    "\n",
    "\n",
    "def trim_cube(d, sh):\n",
    "    if d['cube'].shape != sh:\n",
    "        print(\"trimming\")\n",
    "        print(\"shape\", d['cube'].shape)\n",
    "        d['cube'] = d['cube'][:sh[0], :sh[1], :sh[2]]\n",
    "        print(\"shape\", d['cube'].shape)\n",
    "\n",
    "\n",
    "def load_from_filename_list(fn_list):\n",
    "    cube_list = []\n",
    "    for fn in fn_list:\n",
    "        cube = load_from_file(fn)\n",
    "        cube_list2array(cube)\n",
    "        trim_cube(cube, (180, 180, 240))\n",
    "        cube_list.append(cube)\n",
    "    return cube_list\n",
    "\n",
    "\n",
    "def cube_by_name(all_cubes, name):\n",
    "    for i in range(len(all_cubes)):\n",
    "        if all_cubes[i]['name'] == name:\n",
    "            return all_cubes[i].copy()\n",
    "    return None\n",
    "\n",
    "\n",
    "# próba kontrolna\n",
    "def add_random_cube(all_cubes):\n",
    "    if all_cubes[0]['name'] == 'random_cube':\n",
    "        print('ta seria ma już random_cube!')\n",
    "    else:\n",
    "        c = all_cubes[0]['cube'] # my params\n",
    "        sh0 = len(c)\n",
    "        sh1 = len(c[0])\n",
    "        sh2 = len(c[0][0])\n",
    "        cube_shape = [sh0, sh1, sh2]\n",
    "        cb = cube_shape\n",
    "\n",
    "        random_arr = np.random.rand(cb[0], cb[1], cb[2])\n",
    "        s = np.sum(random_arr)\n",
    "        n_random_photons = 100_000_000\n",
    "        random_arr *= n_random_photons\n",
    "        random_arr /= s\n",
    "\n",
    "        c2 = all_cubes[0]\n",
    "        random_cube = {\n",
    "            \"n_photons\": n_random_photons,\n",
    "            \"overflow\": 0,\n",
    "            \"mu_a\": 1.673,\n",
    "            \"name\": 'random_cube',\n",
    "            \"bins_per_1_cm\": c2['bins_per_1_cm'],\n",
    "            \"cube\": random_arr,\n",
    "            \"photon_weight\": 1.0,\n",
    "            \"normalized_already\": False,\n",
    "            \"file_path\": \"NA\",\n",
    "            \"file_dir_path\": \"NA\",\n",
    "            \"params_type\": \"org_my\"\n",
    "        }\n",
    "\n",
    "        print(random_arr.size)\n",
    "        print(random_arr.shape)\n",
    "        print(random_arr.sum())\n",
    "\n",
    "        all_cubes.insert(0, random_cube)\n",
    "\n",
    "\n",
    "def filter_outliers(arr, q_min=0.01, q_max=0.99):\n",
    "    arr = arr.copy()\n",
    "    if True:\n",
    "        qqmin = np.quantile(arr, q=q_min)\n",
    "        qqmax = np.quantile(arr, q=q_max)\n",
    "        main_ids_out = np.logical_or( (arr < qqmin),  (arr > qqmax) )\n",
    "        s = np.sum(main_ids_out)\n",
    "        val_replace = np.random.choice(arr.flatten(), s)\n",
    "        temp_arr = val_replace\n",
    "        while True:\n",
    "            ids_out = np.logical_or( (temp_arr < qqmin), (temp_arr > qqmax) )\n",
    "            s = np.sum(ids_out)\n",
    "            if s == 0:\n",
    "                arr[main_ids_out] = temp_arr\n",
    "                break\n",
    "            val_replace = np.random.choice(arr.flatten(), s)\n",
    "            temp_arr[ids_out] = val_replace\n",
    "    return arr\n",
    "\n",
    "\n",
    "def simple_hist_plot(arr, range, bins, title=\"\", density=False, norm=False):\n",
    "    # plt.hist(arr, range=range, bins=bins, density=density)\n",
    "    # # plt.yscale(\"log\") # - tutaj dopisać title i opisy osi\n",
    "    # plt.show() #  - zakomentować to\n",
    "    \n",
    "    hist, bin_edges = np.histogram(arr, range=range, bins=bins, density=density)\n",
    "    plt.bar(bin_edges[:-1], hist, width=(bin_edges[1] - bin_edges[0]) * 1.0) # , color='b'\n",
    "    # plt.plot(bin_edges[:-1], hist, c='r')\n",
    "    plt.title('Histogram'+title)\n",
    "    plt.xlabel('transport')\n",
    "    plt.ylabel('ilość próbek')\n",
    "    if norm == \"log\":\n",
    "        plt.yscale(\"log\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def simple_boxplot(arr, title=\"\"):\n",
    "    plt.boxplot(arr)\n",
    "    plt.title('Boxplot'+title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def filter_zeros(arr, typ=None):\n",
    "    arr = arr.copy()\n",
    "    arr[arr == 0] = np.min(arr[arr > 0])\n",
    "    return arr\n",
    "\n",
    "\n",
    "def fun_tan(arr, typ=None):\n",
    "    return -np.tan(arr - np.pi / 2)\n",
    "\n",
    "\n",
    "def fun_tan_wrapper(arr, typ): # łamana\n",
    "    arr = arr.copy()\n",
    "    global max_my\n",
    "    global max_org\n",
    "    global brpoint_my\n",
    "    global brpoint_org\n",
    "\n",
    "    if typ is None:\n",
    "        raise ValueError('Potrzebny typ parametrów danych')\n",
    "    \n",
    "    if 'org' in typ:\n",
    "        maxi_all = max_org\n",
    "        brpoint = brpoint_org\n",
    "    elif 'my' in typ:\n",
    "        maxi_all = max_my\n",
    "        brpoint = brpoint_my\n",
    "    else:\n",
    "        raise ValueError('Potrzebny typ parametrów danych')\n",
    "\n",
    "    # dane od 0 do brpoint trzeba rozciągnąć na zakres 0 do pi/4\n",
    "    # tan(pi/4) = 1\n",
    "    arr = arr.copy()\n",
    "    new_arr = arr.copy()\n",
    "    new_arr[arr <= brpoint] = new_arr[arr <= brpoint] / brpoint * np.pi/4\n",
    "\n",
    "    # dane od brpoint do maxi_all trzeba rozciągnąć na zakres od pi/4 do pi/2\n",
    "    new_arr[arr > brpoint] = (new_arr[arr > brpoint] - brpoint) / (maxi_all-brpoint) * (np.pi/2 - np.pi/4) + np.pi/4\n",
    "\n",
    "    arr = new_arr\n",
    "    arr = fun_tan(arr)\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "def move_mean(arr):\n",
    "    arr = arr.copy()\n",
    "    mea = np.mean(arr)\n",
    "    arr = arr - mea\n",
    "    return arr\n",
    "\n",
    "\n",
    "def move_std(arr):\n",
    "    arr = arr.copy()\n",
    "    mea = np.mean(arr)\n",
    "    st = np.std(arr)\n",
    "    arr = arr - mea\n",
    "    arr = arr / st\n",
    "    arr = arr + mea\n",
    "    return arr\n",
    "\n",
    "\n",
    "def move_mean_std(arr):\n",
    "    arr = arr.copy()\n",
    "    mea = np.mean(arr)\n",
    "    st = np.std(arr)\n",
    "    arr = arr - mea\n",
    "    arr = arr / st\n",
    "    return arr\n",
    "\n",
    "\n",
    "def dump_transformers():\n",
    "\n",
    "    model_dir = 'models'\n",
    "    files = os.listdir(model_dir)\n",
    "    files = [model_dir+'/'+fn for fn in files]\n",
    "    print(files)\n",
    "\n",
    "    global org_quantile_transformer\n",
    "    global org_power_transformer\n",
    "    global org_global_training_arr\n",
    "    global my_quantile_transformer\n",
    "    global my_power_transformer\n",
    "    global my_global_training_arr\n",
    "\n",
    "    # Ścieżki do zapisania modeli\n",
    "    org_quantile_transformer_filename = 'models/org_quantile_transformer.pkl'\n",
    "    org_power_transformer_filename = 'models/org_power_transformer.pkl'\n",
    "    org_global_training_arr_filename = 'models/org_global_training_arr.pkl'\n",
    "    my_quantile_transformer_filename = 'models/my_quantile_transformer.pkl'\n",
    "    my_power_transformer_filename = 'models/my_power_transformer.pkl'\n",
    "    my_global_training_arr_filename = 'models/my_global_training_arr.pkl'\n",
    "\n",
    "    # Zapisanie modeli za pomocą joblib\n",
    "    if org_quantile_transformer is not None and (org_quantile_transformer_filename not in files):\n",
    "        joblib.dump(org_quantile_transformer, org_quantile_transformer_filename)\n",
    "    if org_power_transformer is not None and (org_power_transformer_filename not in files):\n",
    "        joblib.dump(org_power_transformer, org_power_transformer_filename)\n",
    "    if org_global_training_arr is not None and (org_global_training_arr_filename not in files):\n",
    "        joblib.dump(org_global_training_arr, org_global_training_arr_filename)\n",
    "    if my_quantile_transformer is not None and (my_quantile_transformer_filename not in files):\n",
    "        joblib.dump(my_quantile_transformer, my_quantile_transformer_filename)\n",
    "    if my_power_transformer is not None and (my_power_transformer_filename not in files):\n",
    "        joblib.dump(my_power_transformer, my_power_transformer_filename)\n",
    "    if my_global_training_arr is not None and (my_global_training_arr_filename not in files):\n",
    "        joblib.dump(my_global_training_arr, my_global_training_arr_filename)\n",
    "\n",
    "\n",
    "def load_transformers():\n",
    "\n",
    "    model_dir = 'models'\n",
    "    files = os.listdir(model_dir)\n",
    "    files = [model_dir+'/'+fn for fn in files]\n",
    "    print(files)\n",
    "\n",
    "    loaded = 0\n",
    "\n",
    "    global org_quantile_transformer\n",
    "    global org_power_transformer\n",
    "    global org_global_training_arr\n",
    "    global my_quantile_transformer\n",
    "    global my_power_transformer\n",
    "    global my_global_training_arr\n",
    "\n",
    "    # Ścieżki do zapisania modeli\n",
    "    org_quantile_transformer_filename = 'models/org_quantile_transformer.pkl'\n",
    "    org_power_transformer_filename = 'models/org_power_transformer.pkl'\n",
    "    org_global_training_arr_filename = 'models/org_global_training_arr.pkl'\n",
    "    my_quantile_transformer_filename = 'models/my_quantile_transformer.pkl'\n",
    "    my_power_transformer_filename = 'models/my_power_transformer.pkl'\n",
    "    my_global_training_arr_filename = 'models/my_global_training_arr.pkl'\n",
    "\n",
    "    if org_quantile_transformer is None and (org_quantile_transformer_filename in files):\n",
    "        org_quantile_transformer = joblib.load(org_quantile_transformer_filename)\n",
    "        loaded += 1\n",
    "    if org_power_transformer is None and (org_power_transformer_filename in files):\n",
    "        org_power_transformer = joblib.load(org_power_transformer_filename)\n",
    "        loaded += 1\n",
    "    if org_global_training_arr is None and (org_global_training_arr_filename in files):\n",
    "        org_global_training_arr = joblib.load(org_global_training_arr_filename)\n",
    "        loaded += 1\n",
    "    if my_quantile_transformer is None and (my_quantile_transformer_filename in files):\n",
    "        my_quantile_transformer = joblib.load(my_quantile_transformer_filename)\n",
    "        loaded += 1\n",
    "    if my_power_transformer is None and (my_power_transformer_filename in files):\n",
    "        my_power_transformer = joblib.load(my_power_transformer_filename)\n",
    "        loaded += 1\n",
    "    if my_global_training_arr is None and (my_global_training_arr_filename in files):\n",
    "        my_global_training_arr = joblib.load(my_global_training_arr_filename)\n",
    "        loaded += 1\n",
    "\n",
    "    print(f'loaded num {loaded}')\n",
    "    if loaded < 6:\n",
    "        return False\n",
    "    elif loaded == 6:\n",
    "        return True\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "def train_data_transformers(init_arr = None):\n",
    "\n",
    "    if load_transformers():\n",
    "        return True\n",
    "\n",
    "    global quantile_transformer\n",
    "    global power_transformer\n",
    "    global global_training_arr\n",
    "\n",
    "    if quantile_transformer is None or power_transformer is None: # tutaj obsługowany\n",
    "        # jest wyjątek braku ustawienia wcześniej transformerów globalnych\n",
    "        if global_training_arr is None:\n",
    "            if init_arr is None:\n",
    "                raise Exception('Tablica treningowa nie została wcześniej ustawiona ani podana jako argument tej funkcji.')\n",
    "            else:\n",
    "                arr = init_arr.flatten()\n",
    "                arr = np.sort(arr)\n",
    "                arr = filter_outliers(arr)\n",
    "                global_training_arr = arr\n",
    "    else:\n",
    "        print('Wszystkie transformery zostały przetrenowane wcześniej.')\n",
    "\n",
    "    if quantile_transformer is None:\n",
    "        print('Trenowanie quantile transformer.')\n",
    "        rng = np.random.RandomState(304)\n",
    "        # n_quantiles is set to the training set size rather than the default value\n",
    "        # to avoid a warning being raised by this example\n",
    "        n_quantiles = global_training_arr.shape[0]\n",
    "        n_quantiles = 1_000_000\n",
    "        subsample = n_quantiles\n",
    "        qt = QuantileTransformer(\n",
    "        n_quantiles=n_quantiles, output_distribution=\"normal\", random_state=rng, subsample=subsample\n",
    "        )\n",
    "        quantile_transformer = qt.fit(global_training_arr.reshape(-1, 1))\n",
    "        print('Training quantile transformer done.')\n",
    "\n",
    "    if power_transformer is None:\n",
    "        print('Trenowanie power transformer.')\n",
    "        rng = np.random.RandomState(304)\n",
    "        pt = PowerTransformer(method='yeo-johnson')\n",
    "        power_transformer = pt.fit(global_training_arr.reshape(-1, 1))\n",
    "        print('Training power transformer done.')\n",
    "\n",
    "\n",
    "def setup_transformers():\n",
    "    # wczytaj lub wytrenuj i zapisz\n",
    "\n",
    "    global quantile_transformer\n",
    "    global power_transformer\n",
    "    global global_training_arr\n",
    "\n",
    "    global org_quantile_transformer\n",
    "    global org_power_transformer\n",
    "    global org_global_training_arr\n",
    "    global my_quantile_transformer\n",
    "    global my_power_transformer\n",
    "    global my_global_training_arr\n",
    "\n",
    "    quantile_transformer = None\n",
    "    power_transformer = None\n",
    "    global_training_arr = None\n",
    "\n",
    "    org_quantile_transformer = None\n",
    "    org_power_transformer = None\n",
    "    org_global_training_arr = None\n",
    "    my_quantile_transformer = None\n",
    "    my_power_transformer = None\n",
    "    my_global_training_arr = None\n",
    "\n",
    "    if load_transformers():\n",
    "        return True\n",
    "\n",
    "    train_arr = cube_by_name(all_cubes, 'mc456_my_100mln_cube')['cube']\n",
    "    train_data_transformers(init_arr = train_arr)\n",
    "    my_quantile_transformer = quantile_transformer\n",
    "    my_power_transformer = power_transformer\n",
    "    my_global_training_arr = global_training_arr\n",
    "    quantile_transformer = None\n",
    "    power_transformer = None\n",
    "    global_training_arr = None\n",
    "    print('my', my_quantile_transformer)\n",
    "    print('empty', quantile_transformer)\n",
    "\n",
    "    train_arr = cube_by_name(all_cubes, 'mc456_org_100mln_cube')['cube']\n",
    "    train_data_transformers(init_arr = train_arr)\n",
    "    org_quantile_transformer = quantile_transformer\n",
    "    org_power_transformer = power_transformer\n",
    "    org_global_training_arr = global_training_arr\n",
    "    quantile_transformer = None\n",
    "    power_transformer = None\n",
    "    global_training_arr = None\n",
    "\n",
    "    dump_transformers()\n",
    "\n",
    "\n",
    "def ttest_preprocess(arr: np.ndarray, typ, dec=1):\n",
    "\n",
    "    global org_power_transformer\n",
    "    global my_power_transformer\n",
    "    global org_quantile_transformer\n",
    "    global my_quantile_transformer\n",
    "\n",
    "    arr = arr.flatten()\n",
    "\n",
    "    if dec == -1:\n",
    "        return arr\n",
    "\n",
    "    arr = filter_outliers(arr)\n",
    "\n",
    "    if dec == 0:\n",
    "        return arr\n",
    "\n",
    "    if dec == 1:\n",
    "        arr = filter_zeros(arr)\n",
    "        arr = np.log(arr) # najlepszy boxcox lambda = 0, więc lepiej logarytm\n",
    "        return arr\n",
    "\n",
    "    if dec == 2:\n",
    "        arr = fun_tan_wrapper(arr, typ) # przeskalowany logarytm\n",
    "        return arr\n",
    "\n",
    "    if dec == 3:\n",
    "        if 'org' in cub['params_type']:\n",
    "            transformer = org_power_transformer\n",
    "        elif 'my' in cub['params_type']:\n",
    "            transformer = my_power_transformer\n",
    "        transformed_data = transformer.transform(arr.reshape(-1, 1)).reshape(-1)\n",
    "        arr = transformed_data.flatten()\n",
    "        return arr\n",
    "\n",
    "    if dec == 4:\n",
    "        if 'org' in cub['params_type']:\n",
    "            transformer = org_quantile_transformer\n",
    "        elif 'my' in cub['params_type']:\n",
    "            transformer = org_quantile_transformer\n",
    "        transformed_data = transformer.transform(arr.reshape(-1, 1)).reshape(-1)\n",
    "        arr = transformed_data.flatten()\n",
    "        return arr\n",
    "    \n",
    "    raise NotImplementedError('Nie ma takiego dec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eksperymenty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experiment():\n",
    "    def __init__(self, category, experiment_name, benchmark_path, folders):\n",
    "        category = category #\n",
    "        experiment_name = experiment_name #\n",
    "\n",
    "        folders = folders #\n",
    "        filenames = [] #\n",
    "        benchmark_path = benchmark_path #\n",
    "        mu_a = [] #\n",
    "        all_cubes_names = [] #\n",
    "        params_types = [] #\n",
    "\n",
    "        cubes_path = 'CUBES'\n",
    "\n",
    "        file_paths = []\n",
    "\n",
    "\n",
    "    def get_all_cubes_names_from_filenames(self):\n",
    "        for f_list in self.filenames:\n",
    "            this_dir_cube_names = []\n",
    "            for fn in f_list:\n",
    "                cube_name = fn[:-5]\n",
    "                this_dir_cube_names.append(cube_name)\n",
    "            self.all_cubes_names.append(this_dir_cube_names)\n",
    "\n",
    "\n",
    "    def get_filenames_from_folders(self):\n",
    "        for f in self.folders:\n",
    "            path = '/'.join(self.cubes_path, f)\n",
    "            file_list = os.listdir(path)\n",
    "            self.filenames.append(file_list)\n",
    "\n",
    "\n",
    "    def mua_per_dir(self, mua_list):\n",
    "        for mua, fn in zip(mua_list, self.filenames):\n",
    "            self.mu_a.append([mua] * len(fn)) # łączenie tablic\n",
    "\n",
    "\n",
    "    def params_types_per_dir(self, params_types):\n",
    "        for pt, fn in zip(params_types, self.filenames):\n",
    "            self.params_types.append([pt] * len(fn))\n",
    "\n",
    "\n",
    "    def file_paths_from_filenames(self):\n",
    "        for dir_id in range(len(self.folders)):\n",
    "            this_folder_paths = []\n",
    "            for fn_id in range(len(self.filenames[dir_id])):\n",
    "                path = '/'.join(self.cubes_path, self.folders[dir_id], self.filenames[dir_id][fn_id])\n",
    "                this_folder_paths.append(path)\n",
    "            self.file_paths.append(this_folder_paths)\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        # load from files -> all_cubes\n",
    "        all_cubes = []\n",
    "        dir_num = len(self.folders)\n",
    "        for dir_id in range(dir_num):\n",
    "            path_list = self.file_paths[dir_id]\n",
    "            all_cubes += load_from_filename_list(path_list)\n",
    "        \n",
    "        print('================================')\n",
    "        print('len(all_cubes)', len(all_cubes))\n",
    "\n",
    "        # przypisz właściwości podstawowe\n",
    "        all_cubes_names = sum(self.all_cubes_names, []) # łączenie tablic\n",
    "        all_mu_a = sum(self.mu_a, [])\n",
    "        all_filename_list = sum(self.file_paths, [])\n",
    "        all_dir_list = self.folders.copy()\n",
    "        params_types = sum(self.params_types, [])\n",
    "        for cub, name, mu_a, fn, fndir, param_t in zip(all_cubes, all_cubes_names, all_mu_a, all_filename_list, all_dir_list, params_types):\n",
    "            cub['name'] = name\n",
    "            cub['photon_weight'] = 1.0\n",
    "            cub['normalized_already'] = False\n",
    "            cub['mu_a'] = mu_a\n",
    "            cub['file_path'] = fn\n",
    "            cub['file_dir_path'] = fndir\n",
    "            cub['params_type'] = param_t\n",
    "\n",
    "        # jeśli random cube było wcześniej - wyrzucić je\n",
    "        if all_cubes[0]['name'] == 'random_cube':\n",
    "            all_cubes = all_cubes[1:]\n",
    "\n",
    "        # dodaj losową próbę kontrolną\n",
    "        add_random_cube(all_cubes)\n",
    "\n",
    "        # USTAWIANIE WARTOŚCI SKRAJNYCH DO TRANSFORMACJI\n",
    "        max_my = 55\n",
    "        max_org = 105\n",
    "        brpoint_my = 5\n",
    "        brpoint_org = 0.015\n",
    "\n",
    "        # print info\n",
    "        print('================================')\n",
    "        print(\"shape\", all_cubes[0]['cube'].shape)\n",
    "        print(\"size\", all_cubes[0]['cube'].size)\n",
    "        print(\"len\", len(all_cubes))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        quantile_transformer = None\n",
    "        power_transformer = None\n",
    "        global_training_arr = None\n",
    "\n",
    "        org_quantile_transformer = None\n",
    "        org_power_transformer = None\n",
    "        org_global_training_arr = None\n",
    "        my_quantile_transformer = None\n",
    "        my_power_transformer = None\n",
    "        my_global_training_arr = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "python_vs_c = experiment(category = 'porównanie python - język c',\n",
    "                         experiment_name = 'mc456 my_params 10k-100mln'+'_vs_'+'mc456_p my-params 10k-10mln',\n",
    "                         benchmark_path = 'CUBES/mc456 my_params 10k-100mln/mc456_mc_100mln_my_params_cube.json',\n",
    "                         folders = ['mc456 my_params 10k-100mln', 'mc456_p my-params 10k-10mln'],\n",
    "                         )\n",
    "python_vs_c.get_filenames_from_folders()\n",
    "python_vs_c.get_all_cubes_names_from_filenames()\n",
    "python_vs_c.mua_per_dir([1.673, 1.673])\n",
    "python_vs_c.mua_per_dir(['my', 'my'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PORÓWNYWANIE OGÓLNE:\n",
    "\n",
    "mati-sim my_params 10k-100mln\n",
    "mc456 my_params 10k-100mln\n",
    "\n",
    "mati-sim org_params 10k-10mln\n",
    "mc456 org_params 10k-100mln\n",
    "\n",
    "\n",
    "\n",
    "specjalistyczne:\n",
    "\n",
    "mc456 rozne g (0.0-1.0 z krokiem 0.1) 100mln\n",
    "\n",
    "mati-sim my_params 10k g {0, 0.5, 0.9, 1}\n",
    "\n",
    "mc456 rozne_skóry_z_tabeli (8 rodzajów) 100mln\n",
    "\n",
    "mc456 my-params light-sources\n",
    "\n",
    "\n",
    "\n",
    "dodatkowe:\n",
    "\n",
    "mati-sim 2-layers\n",
    "\n",
    "mati-sim 3-layers\n",
    "\n",
    "mati-sim veins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mati-sim 2-layers',\n",
       " 'mati-sim 3-layers',\n",
       " 'mati-sim my_params 10k g {0, 0.5, 0.9, 1}',\n",
       " 'mati-sim my_params 10k-100mln',\n",
       " 'mati-sim org_params 10k-10mln',\n",
       " 'mati-sim veins',\n",
       " 'mc456 my-params light-sources',\n",
       " 'mc456 my_params 10k-100mln',\n",
       " 'mc456 org_params 10k-100mln',\n",
       " 'mc456 rozne g (0.0-1.0 z krokiem 0.1) 100mln',\n",
       " 'mc456 rozne_skóry_z_tabeli (8 rodzajów) 100mln',\n",
       " 'mc456_p my-params 10k-10mln']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('CUBES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[123, 123, 123, 123]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[123]*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porównanie python - język c:\n",
    "\n",
    "mc456 my_params 10k-100mln\n",
    "mc456_p my-params 10k-10mln\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PORÓWNYWANIE OGÓLNE:\n",
    "\n",
    "mati-sim my_params 10k-100mln\n",
    "mc456 my_params 10k-100mln\n",
    "\n",
    "mati-sim org_params 10k-10mln\n",
    "mc456 org_params 10k-100mln\n",
    "\n",
    "\n",
    "\n",
    "specjalistyczne:\n",
    "\n",
    "mc456 rozne g (0.0-1.0 z krokiem 0.1) 100mln\n",
    "\n",
    "mati-sim my_params 10k g {0, 0.5, 0.9, 1}\n",
    "\n",
    "mc456 rozne_skóry_z_tabeli (8 rodzajów) 100mln\n",
    "\n",
    "mc456 my-params light-sources\n",
    "\n",
    "\n",
    "\n",
    "dodatkowe:\n",
    "\n",
    "mati-sim 2-layers\n",
    "\n",
    "mati-sim 3-layers\n",
    "\n",
    "mati-sim veins"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
